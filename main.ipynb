{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac35d750",
   "metadata": {},
   "source": [
    "# Modified 3D PMRNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "754a7290",
   "metadata": {},
   "source": [
    "## Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72812cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import Utils\n",
    "# from skimage import util\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18052c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.3\n"
     ]
    }
   ],
   "source": [
    "#import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cafc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01b53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.ndimage import rotate\n",
    "# # import scipy\n",
    "# # print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7007d9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96600a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotaxis = [\n",
    "#     [0, 0, 0],\n",
    "#     [90, 0, 0],\n",
    "#     [0, 90, 0],\n",
    "# ]\n",
    "# cube = np.ones((10, 10, 10))\n",
    "\n",
    "# for rot in rotaxis:\n",
    "#     rotated_cube = cube\n",
    "#     for i in range(3):\n",
    "#         rotated_cube = rotate(rotated_cube, angle=rot[i], axes=i, mode='constant', cval=0.0)\n",
    "#     print(rotated_cube.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507234b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb814b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea03e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95dc6667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a03177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,losses,Sequential,metrics\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import optimizers \n",
    "from tensorflow.keras.optimizers import * \n",
    "# from tensorflow.keras.optimizers.experimental import SGD\n",
    "from tensorflow.image import ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e1eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e016aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CBAM import ConvolutionBlockAttentionModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50bda7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ffd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow._api.v2.compat.v1 as tf1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3060e561",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce6e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    \"LEARNING_RATE\": 1e-3,\n",
    "    \"OPTIMIZER\":'Adam',\n",
    "    \"N_EPOCHS\": 2,\n",
    "    \"N_FILTERS\": 5,\n",
    "    \"INPUT_SHAPE\":(256,256,1),\n",
    "    \"LATENT_SPACE_DIM\" : 64,\n",
    "    \"REDUCED_DIMENSION\" : 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2c564b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIGURATION[\"OPTIMIZER\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19893387",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e52f3713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data = Utils.read_data(\"Berea_2d25um_binary.raw\")\n",
    "image_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eec28ea2",
   "metadata": {},
   "source": [
    "## Voxel extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40f1e78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 250, 256, 256, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxels = Utils.extract_subvolumes(image_data)\n",
    "voxels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0405903",
   "metadata": {},
   "outputs": [],
   "source": [
    "del image_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db7c40f1",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba0ca25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kl_loss(model):\n",
    "    def _calculate_kl_loss(*args):\n",
    "        kld = tf.keras.losses.KLDivergence()\n",
    "        kl_loss = kld(model.inferenceDistribution,model.learnedDistribution)\n",
    "        return tf.abs(kl_loss)\n",
    "    return _calculate_kl_loss\n",
    "\n",
    "def _calculate_reconstruction_loss(y_target, y_predicted):\n",
    "    mse = losses.MeanSquaredError()\n",
    "    reconstruction_loss = mse( y_target, y_predicted )\n",
    "    return reconstruction_loss\n",
    "\n",
    "# def _calculate_reconstruction_loss(y_target, y_predicted):\n",
    "#     ssim_loss = 1 - tf.reduce_mean(ssim(y_target, y_predicted, max_val=1.0))\n",
    "#     return ssim_loss\n",
    "\n",
    "\n",
    "def _calculate_porosity_loss(y_target,y_predicted):\n",
    "    por1 = tf.reduce_mean(y_target,axis=(1, 2))\n",
    "    por2 = tf.reduce_mean(y_predicted,axis=(1, 2))\n",
    "    mae = losses.MeanAbsoluteError()\n",
    "    return mae(por1,por2)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48e6f2a8",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "789e98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EncoderBlock(Model):\n",
    "#      def __init__(self,n_filter) -> None:\n",
    "#         super(EncoderBlock,self).__init__()\n",
    "#         self.conv = layers.Conv2D(n_filter, (3,3) , activation='relu',\n",
    "#                                padding='same' , name=\"first_encoder_conv\")\n",
    "#         self.bn = layers.BatchNormalization()\n",
    "#         self.mp = layers.MaxPooling2D((2,2), padding='same')\n",
    "            \n",
    "#     def call(self,X):\n",
    "#         X = self.conv(X)\n",
    "#         b = self.bn(X)\n",
    "#         y = self.mp(b)\n",
    "#         return y,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de885cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DecoderBlock(Model):\n",
    "#     def __init__(self,n_filter,skip) ->None:\n",
    "#         super(DecoderBlock,self).__init__()\n",
    "#         self.convT = layers.Conv2DTranspose(n_filter, (3,3), strides=2, activation='relu'\n",
    "#                                          , padding='same',name=\"first_decoder_conv\")\n",
    "#         self.bn = layers.BatchNormalization()\n",
    "#     def call(self,X):\n",
    "#         X = self.convT(X)\n",
    "#         b = self.bn(X)\n",
    "#         b = layers.Add()([b,skip])\n",
    "#         return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f8cb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Encoder(Model):\n",
    "#     def __init__(self,n_blocks,Filter,latentSpace) -> None:\n",
    "#         super(Encoder,self).__init__()\n",
    "#         self.flatten = layers.Flatten()\n",
    "        \n",
    "#         self.latentDense = layers.Dense(latentSpace,name =\"latent_dense\")\n",
    "#         self.bn = layers.BatchNormalization()\n",
    "#         self.encBlocks = [EncoderBlock(Filter * (i+1)) for i in range(n_blocks)]\n",
    "        \n",
    "#     def call(self,X):\n",
    "#         for i in range(n_blocks):\n",
    "#             X = self.encBlocks[i]\n",
    "#         X = self.flatten(X)\n",
    "#         X = self.latentDense(X)\n",
    "#         b = self.bn(X)\n",
    "#         return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28e6da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 * 2 ** (CONFIGURATION[\"N_FILTERS\"]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4d23c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reconstruction():\n",
    "    \"\"\"\n",
    "    Reconstruction represents a Deep Convolutional variational autoencoder architecture\n",
    "    with mirrored encoder and decoder components.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 inputShape=CONFIGURATION[\"INPUT_SHAPE\"],\n",
    "                 latent_space_dim = CONFIGURATION[\"LATENT_SPACE_DIM\"],\n",
    "                 reducedDimension = CONFIGURATION[\"REDUCED_DIMENSION\"],\n",
    "                 num_conv_layers = CONFIGURATION[\"N_FILTERS\"],\n",
    "                 learning_rate = CONFIGURATION[\"LEARNING_RATE\"],\n",
    "                 batch_size = CONFIGURATION[\"BATCH_SIZE\"],\n",
    "                 epochs = CONFIGURATION[\"N_EPOCHS\"],\n",
    "                 opt = CONFIGURATION[\"OPTIMIZER\"],\n",
    "                )-> None:\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##### inputs ######\n",
    "        self.inputShape = inputShape # [256, 256, 1]\n",
    "        self.latent_space_dim = latent_space_dim # 64\n",
    "        self.reducedDimension = reducedDimension #256\n",
    "        self.num_conv_layers = num_conv_layers #5\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.opt = opt\n",
    "#         self.optimizer = getattr(optimizers, opt)(lr = learning_rate) \n",
    "        self.optimizers = {\n",
    "            'SGD' : SGD, \n",
    "            'RMSprop' : RMSprop,\n",
    "            'Adagrad' : Adagrad,\n",
    "            'Adadelta' : Adadelta,\n",
    "            'Adam' : Adam,\n",
    "            'Adamax' : Adamax,\n",
    "            'Nadam' : Nadam,\n",
    "        }\n",
    "        self.reshapeDims = self.inputShape[0] // 2**self.num_conv_layers\n",
    "        self.last_filter = 16 * 2 ** (self.num_conv_layers-1)\n",
    "        \n",
    "        ##### Loss weights ######\n",
    "        self.reconstruction_loss_weight = 1\n",
    "        self.Kullback_leibler_weight = 0.001\n",
    "        self.porosity_Loss_weight = 1\n",
    "        \n",
    "        self.skipConnections = None\n",
    "\n",
    "        self.learnedPrior = None\n",
    "        self.inference = None\n",
    "        self.Generate = None\n",
    "        self.Reconstruction=None\n",
    "\n",
    "        self.skipConnections = []\n",
    "        \n",
    "        self.learnedDistribution = None\n",
    "        self.inferenceDistribution = None\n",
    "        \n",
    "        self._build()\n",
    "\n",
    "    def summary(self):\n",
    "        self.learnedPrior.summary()\n",
    "        self.inference.summary()\n",
    "        self.Generate.summary()\n",
    "        self.Reconstruction.summary()\n",
    "    \n",
    "    def compile(self):\n",
    "        optimizer = self.optimizers[self.opt](learning_rate=self.learning_rate)\n",
    "        self.Reconstruction.compile(optimizer=optimizer,\n",
    "                           loss=self._calculate_combined_loss,\n",
    "                           metrics=[_calculate_reconstruction_loss,\n",
    "                                    _calculate_porosity_loss,\n",
    "                                    calculate_kl_loss(self)],\n",
    "                             experimental_run_tf_function=False)\n",
    "    \n",
    "    def train(self, inputs1,inputs2):\n",
    "        return self.Reconstruction.fit(x=[inputs1,inputs2],\n",
    "                       y=inputs2,\n",
    "                       batch_size=self.batch_size,\n",
    "                       epochs=self.epochs,\n",
    "                       )\n",
    "\n",
    "\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.Reconstruction.load_weights(weights_path)\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        reconstruction = Reconstruction(*parameters)\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        reconstruction.load_weights(weights_path)\n",
    "        return reconstruction\n",
    "\n",
    "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.inputShape,\n",
    "            self.latent_space_dim,\n",
    "            self.reducedDimension,\n",
    "            self.num_conv_layers,\n",
    "            self.learning_rate,\n",
    "            self.batch_size,\n",
    "            self.epochs,\n",
    "            self.opt,\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(parameters, f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.Reconstruction.save_weights(save_path)\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
    "        \n",
    "        \n",
    "        reconstruction_loss = _calculate_reconstruction_loss(y_target,y_predicted)\n",
    "        kl_loss = calculate_kl_loss(self)(self.inferenceDistribution, self.learnedDistribution)\n",
    "        porisity_loss = _calculate_porosity_loss(y_target, y_predicted)\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
    "                                                         + kl_loss * self.Kullback_leibler_weight\\\n",
    "                                                         + porisity_loss * self.porosity_Loss_weight\n",
    "        return combined_loss\n",
    "    \n",
    "\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_inference(self.num_conv_layers)\n",
    "        self._build_learned_prior(self.num_conv_layers)\n",
    "        self._build_generate(self.num_conv_layers)\n",
    "        self._build_reconstruction()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ######  inference ########\n",
    "        \n",
    "    def _build_inference(self,num_conv_layers):\n",
    "        inference_input = layers.Input(shape=self.inputShape, name=\"inference_input\")\n",
    "        \n",
    "        ### ------------------------------------ Encoder ---------------------------------------------\n",
    "        \n",
    "        x = inference_input\n",
    "        for i in range(num_conv_layers):\n",
    "            conv = layers.Conv2D(16 * 2 ** i, (3, 3), activation='relu', padding='same', name=f\"encoder_conv_{i+1}\")(x)\n",
    "            bn = layers.BatchNormalization()(conv)\n",
    "            mp = layers.MaxPooling2D((2, 2), padding='same')(bn)\n",
    "            x = mp\n",
    "   \n",
    "        \n",
    "        flattened = layers.Flatten()(x)\n",
    "        \n",
    "        latentDense = layers.Dense(self.reducedDimension,name =\"latent_dense\")(flattened)\n",
    "        conv_out = layers.BatchNormalization()(latentDense)\n",
    "        \n",
    "    \n",
    "        reshaped = layers.Reshape((1, self.reducedDimension))(conv_out)\n",
    "        inferenceDist = layers.LSTM(self.latent_space_dim, return_sequences=True, name=\"inference_LSTM\")(reshaped)\n",
    "       \n",
    "        self.inference = Model(inference_input, inferenceDist, name=\"inference\")\n",
    "        \n",
    "        \n",
    "    ######   learned prior ########\n",
    "        \n",
    "    def _build_learned_prior(self,num_conv_layers):\n",
    "        learned_input = layers.Input(shape=self.inputShape, name=\"learned_prior_input\")\n",
    "        \n",
    "        ### ------------------------------------ Encoder ---------------------------------------------\n",
    "        \n",
    "        x = learned_input\n",
    "        for i in range(num_conv_layers):\n",
    "            conv = layers.Conv2D(16 * 2 ** i, (3, 3), activation='relu', padding='same', name=f\"encoder_conv_{i+1}\")(x)\n",
    "            bn = layers.BatchNormalization()(conv)\n",
    "            mp = layers.MaxPooling2D((2, 2), padding='same')(bn)\n",
    "            x = mp\n",
    "        \n",
    "        flattened = layers.Flatten()(x)\n",
    "        \n",
    "        latentDense = layers.Dense(self.reducedDimension,name =\"latent_dense\")(flattened)\n",
    "        conv_out = layers.BatchNormalization()(latentDense)\n",
    "        \n",
    "        \n",
    "        \n",
    "        reshaped = layers.Reshape((1, self.reducedDimension))(conv_out)\n",
    "        learned_dist = layers.LSTM(self.latent_space_dim, return_sequences=True,name=\"learned_LSTM\")(reshaped)\n",
    "        self.learnedPrior = Model(learned_input, learned_dist, name=\"learned_prior\")\n",
    "    \n",
    "    #### generate ######\n",
    "    \n",
    "    def _build_generate(self,num_conv_layers):\n",
    "        \n",
    "\n",
    "        \n",
    "        input_generate = layers.Input(shape=self.inputShape, name=\"generate_input\")\n",
    "        learnedDist = layers.Input(shape=(1,self.latent_space_dim), name=\"gen_learned_input\")\n",
    "        \n",
    "        ### ------------------------------------ Encoder ---------------------------------------------\n",
    "        \n",
    "        x = input_generate\n",
    "        for i in range(num_conv_layers):\n",
    "            conv = layers.Conv2D(16 * 2 ** i, (3, 3), activation='relu', padding='same', name=f\"encoder_conv_{i+1}\")(x)\n",
    "            bn = layers.BatchNormalization()(conv)\n",
    "            mp = layers.MaxPooling2D((2, 2), padding='same')(bn)\n",
    "            x = mp\n",
    "            self.skipConnections.append(bn)\n",
    "\n",
    "        \n",
    "        flattened = layers.Flatten()(x)\n",
    "        \n",
    "        latentDense = layers.Dense(self.reducedDimension,name =\"latent_dense\")(flattened)\n",
    "        conv_out = layers.BatchNormalization()(latentDense)\n",
    "        \n",
    "        temp = layers.Reshape(( 1 ,self.reducedDimension ))(conv_out)\n",
    "        \n",
    "        concated_input = layers.Concatenate(axis=-1)([temp,learnedDist])\n",
    "        \n",
    "        reshaped = layers.Reshape((1, self.reducedDimension + self.latent_space_dim))(concated_input)\n",
    "        \n",
    "        generated = layers.LSTM(self.reducedDimension, return_sequences=True,name=\"generate_LSTM\")(reshaped)\n",
    "        \n",
    "        ### ------------------------------------ Decoder ---------------------------------------------\n",
    "        \n",
    "        upDense = layers.Dense(self.reshapeDims*self.reshapeDims*self.last_filter,name=\"up_dense\")(generated)\n",
    "        batchNorm_7 = layers.BatchNormalization()(upDense)\n",
    "        \n",
    "        reshapedUp = layers.Reshape((self.reshapeDims,self.reshapeDims,self.last_filter))(batchNorm_7)\n",
    "        \n",
    "        \n",
    "        \n",
    "        generated = reshapedUp\n",
    "        for i in reversed(range(num_conv_layers)):\n",
    "            convT = layers.Conv2DTranspose(16 * 2 ** i, (3, 3), strides=2, activation='relu',\n",
    "                                           padding='same', name=f\"decoder_conv_{i+1}\")(generated)\n",
    "            bn = layers.BatchNormalization()(convT)\n",
    "            skip_conn = self.skipConnections.pop()\n",
    "            bn = layers.Add()([bn, skip_conn])\n",
    "            generated = ConvolutionBlockAttentionModule()(bn)\n",
    "        \n",
    "        \n",
    "        gen_out = layers.Conv2DTranspose(1, (3,3), activation='sigmoid', padding='same')(generated)\n",
    "        \n",
    "        self.Generate = Model([input_generate,learnedDist], gen_out, name=\"generate\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _build_reconstruction(self):\n",
    "        input_learned = layers.Input(shape=self.inputShape, name=\"learned_input\")\n",
    "        input_inference = layers.Input(shape=self.inputShape, name=\"inference_input\")\n",
    "        \n",
    "\n",
    "        \n",
    "        self.learnedDistribution = self.learnedPrior(input_learned)\n",
    "        self.inferenceDistribution = self.inference(input_inference)\n",
    "        gen_out = self.Generate([input_learned,self.learnedDistribution])\n",
    "        \n",
    "        self.Reconstruction = Model([input_learned,input_inference],gen_out,name=\"reconstuction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b3ce7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.optimizer_v2.gradient_descent.SGD"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers = {\n",
    "            'SGD' : SGD, \n",
    "            'RMSprop' : RMSprop,\n",
    "            'Adagrad' : Adagrad,\n",
    "            'Adadelta' : Adadelta,\n",
    "            'Adam' : Adam,\n",
    "            'Adamax' : Adamax,\n",
    "            'Nadam' : Nadam,\n",
    "        }\n",
    "optimizers['SGD']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39b13c5c",
   "metadata": {},
   "source": [
    "## TensorFlow gpu setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "638ae073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "device = tf.config.list_physical_devices(\"GPU\")\n",
    "print(device)\n",
    "tf.config.experimental.set_memory_growth(device[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4da3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59464a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56d187f0",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "529bf990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\envs\\PFE\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:Layer inference_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer learned_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer generate_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"learned_prior\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "learned_prior_input (InputLa [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 256, 256, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256, 256, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_4 (Conv2D)      (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_5 (Conv2D)      (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "latent_dense (Dense)         (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "learned_LSTM (LSTM)          (None, 1, 64)             82176     \n",
      "=================================================================\n",
      "Total params: 4,672,064\n",
      "Trainable params: 4,670,560\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n",
      "Model: \"inference\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inference_input (InputLayer) [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 256, 256, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_4 (Conv2D)      (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_5 (Conv2D)      (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "latent_dense (Dense)         (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "inference_LSTM (LSTM)        (None, 1, 64)             82176     \n",
      "=================================================================\n",
      "Total params: 4,672,064\n",
      "Trainable params: 4,670,560\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n",
      "Model: \"generate\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "generate_input (InputLayer)     [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 256, 256, 16) 160         generate_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256, 256, 16) 64          encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 128, 128, 16) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 128, 128, 32) 4640        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 32) 128         encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 64, 64, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 64, 64, 64)   18496       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 32, 32, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_4 (Conv2D)         (None, 32, 32, 128)  73856       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 128)  512         encoder_conv_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_5 (Conv2D)         (None, 16, 16, 256)  295168      max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 256)  1024        encoder_conv_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 256)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 16384)        0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "latent_dense (Dense)            (None, 256)          4194560     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256)          1024        latent_dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 256)       0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gen_learned_input (InputLayer)  [(None, 1, 64)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 320)       0           reshape_2[0][0]                  \n",
      "                                                                 gen_learned_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 320)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "generate_LSTM (LSTM)            (None, 1, 256)       590848      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_dense (Dense)                (None, 1, 16384)     4210688     generate_LSTM[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 1, 16384)     65536       up_dense[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 8, 8, 256)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "decoder_conv_5 (Conv2DTranspose (None, 16, 16, 256)  590080      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 256)  1024        decoder_conv_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 16, 256)  0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "convolution_block_attention_mod (None, 16, 16, 256)  2137        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_conv_4 (Conv2DTranspose (None, 32, 32, 128)  295040      convolution_block_attention_modul\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 128)  512         decoder_conv_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 128)  0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "convolution_block_attention_mod (None, 32, 32, 128)  1113        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_conv_3 (Conv2DTranspose (None, 64, 64, 64)   73792       convolution_block_attention_modul\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 64)   256         decoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "convolution_block_attention_mod (None, 64, 64, 64)   601         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_conv_2 (Conv2DTranspose (None, 128, 128, 32) 18464       convolution_block_attention_modul\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 32) 128         decoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 32) 0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "convolution_block_attention_mod (None, 128, 128, 32) 345         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_conv_1 (Conv2DTranspose (None, 256, 256, 16) 4624        convolution_block_attention_modul\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256, 256, 16) 64          decoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256, 256, 16) 0           batch_normalization_23[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "convolution_block_attention_mod (None, 256, 256, 16) 217         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 256, 256, 1)  145         convolution_block_attention_modul\n",
      "==================================================================================================\n",
      "Total params: 10,445,502\n",
      "Trainable params: 10,410,238\n",
      "Non-trainable params: 35,264\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"reconstuction\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "learned_input (InputLayer)      [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "learned_prior (Functional)      (None, 1, 64)        4672064     learned_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inference_input (InputLayer)    [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generate (Functional)           (None, 256, 256, 1)  10445502    learned_input[0][0]              \n",
      "                                                                 learned_prior[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 15,117,566\n",
      "Trainable params: 15,080,798\n",
      "Non-trainable params: 36,768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reconstruction = Reconstruction()\n",
    "reconstruction.summary()\n",
    "reconstruction.compile()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf36c49a",
   "metadata": {},
   "source": [
    "## train and test data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fec518e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = voxels[:-6]\n",
    "X_test = voxels[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdef105b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2a93f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37b159f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del voxels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "179a558f",
   "metadata": {},
   "source": [
    "## Creating model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37376c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "learnedVoxels = []\n",
    "inferenceVoxels = []\n",
    "for voxel in X_train:\n",
    "    learnedVoxels.append(voxel[:-1])\n",
    "    inferenceVoxels.append(voxel[1:])\n",
    "\n",
    "# learnedVoxels = np.array(learnedVoxels)\n",
    "# inferenceVoxels = np.array(inferenceVoxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fbabbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer inference_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer learned_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer generate_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "currently working one voxel : 1, voxels left : 57 \n",
      "Train on 249 samples\n",
      "Epoch 1/30\n",
      "249/249 [==============================] - 10s 39ms/sample - loss: 0.1881 - _calculate_reconstruction_loss: 0.0574 - _calculate_porosity_loss: 0.0435 - _calculate_kl_loss: 84.3780\n",
      "Epoch 2/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0879 - _calculate_reconstruction_loss: 0.0278 - _calculate_porosity_loss: 0.0037 - _calculate_kl_loss: 56.6588\n",
      "Epoch 3/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0827 - _calculate_reconstruction_loss: 0.0275 - _calculate_porosity_loss: 0.0042 - _calculate_kl_loss: 50.9520\n",
      "Epoch 4/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0802 - _calculate_reconstruction_loss: 0.0270 - _calculate_porosity_loss: 0.0038 - _calculate_kl_loss: 49.8039\n",
      "Epoch 5/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0786 - _calculate_reconstruction_loss: 0.0266 - _calculate_porosity_loss: 0.0040 - _calculate_kl_loss: 48.1152\n",
      "Epoch 6/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0653 - _calculate_reconstruction_loss: 0.0260 - _calculate_porosity_loss: 0.0037 - _calculate_kl_loss: 35.2038\n",
      "Epoch 7/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0563 - _calculate_reconstruction_loss: 0.0252 - _calculate_porosity_loss: 0.0038 - _calculate_kl_loss: 26.9971\n",
      "Epoch 8/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0508 - _calculate_reconstruction_loss: 0.0245 - _calculate_porosity_loss: 0.0037 - _calculate_kl_loss: 23.0448\n",
      "Epoch 9/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0485 - _calculate_reconstruction_loss: 0.0237 - _calculate_porosity_loss: 0.0040 - _calculate_kl_loss: 20.4551\n",
      "Epoch 10/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0453 - _calculate_reconstruction_loss: 0.0227 - _calculate_porosity_loss: 0.0036 - _calculate_kl_loss: 20.1750\n",
      "Epoch 11/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0419 - _calculate_reconstruction_loss: 0.0220 - _calculate_porosity_loss: 0.0054 - _calculate_kl_loss: 14.5169\n",
      "Epoch 12/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0423 - _calculate_reconstruction_loss: 0.0208 - _calculate_porosity_loss: 0.0036 - _calculate_kl_loss: 18.9829\n",
      "Epoch 13/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0493 - _calculate_reconstruction_loss: 0.0201 - _calculate_porosity_loss: 0.0040 - _calculate_kl_loss: 26.3855\n",
      "Epoch 14/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0526 - _calculate_reconstruction_loss: 0.0192 - _calculate_porosity_loss: 0.0047 - _calculate_kl_loss: 29.5727\n",
      "Epoch 15/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0416 - _calculate_reconstruction_loss: 0.0183 - _calculate_porosity_loss: 0.0038 - _calculate_kl_loss: 19.8144\n",
      "Epoch 16/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0426 - _calculate_reconstruction_loss: 0.0177 - _calculate_porosity_loss: 0.0046 - _calculate_kl_loss: 21.0900\n",
      "Epoch 17/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0359 - _calculate_reconstruction_loss: 0.0167 - _calculate_porosity_loss: 0.0042 - _calculate_kl_loss: 15.6176\n",
      "Epoch 18/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0349 - _calculate_reconstruction_loss: 0.0163 - _calculate_porosity_loss: 0.0043 - _calculate_kl_loss: 14.9806\n",
      "Epoch 19/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0296 - _calculate_reconstruction_loss: 0.0156 - _calculate_porosity_loss: 0.0036 - _calculate_kl_loss: 10.4461\n",
      "Epoch 20/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0255 - _calculate_reconstruction_loss: 0.0152 - _calculate_porosity_loss: 0.0038 - _calculate_kl_loss: 6.5650\n",
      "Epoch 21/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0242 - _calculate_reconstruction_loss: 0.0147 - _calculate_porosity_loss: 0.0035 - _calculate_kl_loss: 6.0255\n",
      "Epoch 22/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0239 - _calculate_reconstruction_loss: 0.0142 - _calculate_porosity_loss: 0.0037 - _calculate_kl_loss: 6.1524\n",
      "Epoch 23/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0240 - _calculate_reconstruction_loss: 0.0138 - _calculate_porosity_loss: 0.0034 - _calculate_kl_loss: 6.8175\n",
      "Epoch 24/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0222 - _calculate_reconstruction_loss: 0.0135 - _calculate_porosity_loss: 0.0039 - _calculate_kl_loss: 4.7684\n",
      "Epoch 25/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0190 - _calculate_reconstruction_loss: 0.0130 - _calculate_porosity_loss: 0.0035 - _calculate_kl_loss: 2.5685\n",
      "Epoch 26/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0191 - _calculate_reconstruction_loss: 0.0126 - _calculate_porosity_loss: 0.0033 - _calculate_kl_loss: 3.1336\n",
      "Epoch 27/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0194 - _calculate_reconstruction_loss: 0.0125 - _calculate_porosity_loss: 0.0034 - _calculate_kl_loss: 3.5150\n",
      "Epoch 28/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0167 - _calculate_reconstruction_loss: 0.0119 - _calculate_porosity_loss: 0.0032 - _calculate_kl_loss: 1.7257\n",
      "Epoch 29/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0178 - _calculate_reconstruction_loss: 0.0117 - _calculate_porosity_loss: 0.0036 - _calculate_kl_loss: 2.4652\n",
      "Epoch 30/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0167 - _calculate_reconstruction_loss: 0.0114 - _calculate_porosity_loss: 0.0032 - _calculate_kl_loss: 2.1980\n",
      "currently working one voxel : 2, voxels left : 56 \n",
      "Train on 249 samples\n",
      "Epoch 1/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0313 - _calculate_reconstruction_loss: 0.0259 - _calculate_porosity_loss: 0.0030 - _calculate_kl_loss: 2.2824\n",
      "Epoch 2/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0260 - _calculate_reconstruction_loss: 0.0209 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 2.3718\n",
      "Epoch 3/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0238 - _calculate_reconstruction_loss: 0.0183 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 2.5179\n",
      "Epoch 4/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0225 - _calculate_reconstruction_loss: 0.0168 - _calculate_porosity_loss: 0.0032 - _calculate_kl_loss: 2.5918\n",
      "Epoch 5/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0198 - _calculate_reconstruction_loss: 0.0155 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 1.6991\n",
      "Epoch 6/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0194 - _calculate_reconstruction_loss: 0.0145 - _calculate_porosity_loss: 0.0031 - _calculate_kl_loss: 1.7484\n",
      "Epoch 7/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0188 - _calculate_reconstruction_loss: 0.0138 - _calculate_porosity_loss: 0.0032 - _calculate_kl_loss: 1.9792\n",
      "Epoch 8/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0188 - _calculate_reconstruction_loss: 0.0130 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 2.8263\n",
      "Epoch 9/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0184 - _calculate_reconstruction_loss: 0.0125 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 3.3057\n",
      "Epoch 10/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0179 - _calculate_reconstruction_loss: 0.0122 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 2.8767\n",
      "Epoch 11/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0206 - _calculate_reconstruction_loss: 0.0118 - _calculate_porosity_loss: 0.0030 - _calculate_kl_loss: 5.7883\n",
      "Epoch 12/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0179 - _calculate_reconstruction_loss: 0.0114 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 3.6000\n",
      "Epoch 13/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0167 - _calculate_reconstruction_loss: 0.0110 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 2.7955\n",
      "Epoch 14/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0155 - _calculate_reconstruction_loss: 0.0108 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.9754\n",
      "Epoch 15/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0148 - _calculate_reconstruction_loss: 0.0104 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.7669\n",
      "Epoch 16/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0143 - _calculate_reconstruction_loss: 0.0102 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.4306\n",
      "Epoch 17/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0144 - _calculate_reconstruction_loss: 0.0098 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 2.0354\n",
      "Epoch 18/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0141 - _calculate_reconstruction_loss: 0.0096 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.7907\n",
      "Epoch 19/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0140 - _calculate_reconstruction_loss: 0.0094 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 2.1187\n",
      "Epoch 20/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0143 - _calculate_reconstruction_loss: 0.0092 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 2.1344\n",
      "Epoch 21/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0134 - _calculate_reconstruction_loss: 0.0091 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.7461\n",
      "Epoch 22/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0138 - _calculate_reconstruction_loss: 0.0088 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 2.0634\n",
      "Epoch 23/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0127 - _calculate_reconstruction_loss: 0.0087 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.4800\n",
      "Epoch 24/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0126 - _calculate_reconstruction_loss: 0.0085 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.4882\n",
      "Epoch 25/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0122 - _calculate_reconstruction_loss: 0.0083 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.3011\n",
      "Epoch 26/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0127 - _calculate_reconstruction_loss: 0.0081 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 2.1122\n",
      "Epoch 27/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0116 - _calculate_reconstruction_loss: 0.0079 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.6556\n",
      "Epoch 28/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0121 - _calculate_reconstruction_loss: 0.0080 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 1.2814\n",
      "Epoch 29/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0118 - _calculate_reconstruction_loss: 0.0077 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 1.6781\n",
      "Epoch 30/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0117 - _calculate_reconstruction_loss: 0.0075 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.7049\n",
      "currently working one voxel : 3, voxels left : 55 \n",
      "Train on 249 samples\n",
      "Epoch 1/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0297 - _calculate_reconstruction_loss: 0.0247 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 2.0586\n",
      "Epoch 2/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0235 - _calculate_reconstruction_loss: 0.0194 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.9266\n",
      "Epoch 3/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0212 - _calculate_reconstruction_loss: 0.0165 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 2.1250\n",
      "Epoch 4/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0199 - _calculate_reconstruction_loss: 0.0148 - _calculate_porosity_loss: 0.0030 - _calculate_kl_loss: 2.0400\n",
      "Epoch 5/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0179 - _calculate_reconstruction_loss: 0.0135 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 1.5702\n",
      "Epoch 6/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0160 - _calculate_reconstruction_loss: 0.0125 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.0320\n",
      "Epoch 7/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0158 - _calculate_reconstruction_loss: 0.0119 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.2778\n",
      "Epoch 8/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0155 - _calculate_reconstruction_loss: 0.0112 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.8493\n",
      "Epoch 9/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0161 - _calculate_reconstruction_loss: 0.0107 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 2.7218\n",
      "Epoch 10/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0149 - _calculate_reconstruction_loss: 0.0104 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.9449\n",
      "Epoch 11/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0139 - _calculate_reconstruction_loss: 0.0099 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.7106\n",
      "Epoch 12/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0137 - _calculate_reconstruction_loss: 0.0096 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 1.3753\n",
      "Epoch 13/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0136 - _calculate_reconstruction_loss: 0.0093 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.7807\n",
      "Epoch 14/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0132 - _calculate_reconstruction_loss: 0.0089 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 2.0781\n",
      "Epoch 15/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0127 - _calculate_reconstruction_loss: 0.0086 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.7624\n",
      "Epoch 16/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0124 - _calculate_reconstruction_loss: 0.0084 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.6689\n",
      "Epoch 17/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0123 - _calculate_reconstruction_loss: 0.0081 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.8962\n",
      "Epoch 18/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0116 - _calculate_reconstruction_loss: 0.0080 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 1.1991\n",
      "Epoch 19/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0121 - _calculate_reconstruction_loss: 0.0077 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.9221\n",
      "Epoch 20/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0113 - _calculate_reconstruction_loss: 0.0075 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.6529\n",
      "Epoch 21/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0113 - _calculate_reconstruction_loss: 0.0074 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.4969\n",
      "Epoch 22/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0113 - _calculate_reconstruction_loss: 0.0073 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.7532\n",
      "Epoch 23/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0110 - _calculate_reconstruction_loss: 0.0071 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 1.4927\n",
      "Epoch 24/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0101 - _calculate_reconstruction_loss: 0.0069 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.0771\n",
      "Epoch 25/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0109 - _calculate_reconstruction_loss: 0.0068 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 2.0976\n",
      "Epoch 26/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0106 - _calculate_reconstruction_loss: 0.0066 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.8881\n",
      "Epoch 27/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0105 - _calculate_reconstruction_loss: 0.0066 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.7944\n",
      "Epoch 28/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0095 - _calculate_reconstruction_loss: 0.0064 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.0288\n",
      "Epoch 29/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0100 - _calculate_reconstruction_loss: 0.0062 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.6850\n",
      "Epoch 30/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0097 - _calculate_reconstruction_loss: 0.0061 - _calculate_porosity_loss: 0.0019 - _calculate_kl_loss: 1.6952\n",
      "currently working one voxel : 4, voxels left : 54 \n",
      "Train on 249 samples\n",
      "Epoch 1/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0296 - _calculate_reconstruction_loss: 0.0256 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 1.2367\n",
      "Epoch 2/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0237 - _calculate_reconstruction_loss: 0.0201 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.3686\n",
      "Epoch 3/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0210 - _calculate_reconstruction_loss: 0.0169 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 1.1394\n",
      "Epoch 4/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0190 - _calculate_reconstruction_loss: 0.0149 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 1.4681\n",
      "Epoch 5/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0178 - _calculate_reconstruction_loss: 0.0137 - _calculate_porosity_loss: 0.0032 - _calculate_kl_loss: 1.1515\n",
      "Epoch 6/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0169 - _calculate_reconstruction_loss: 0.0126 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.6151\n",
      "Epoch 7/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0156 - _calculate_reconstruction_loss: 0.0119 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.1490\n",
      "Epoch 8/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0155 - _calculate_reconstruction_loss: 0.0113 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.4139\n",
      "Epoch 9/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0152 - _calculate_reconstruction_loss: 0.0107 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 1.8841\n",
      "Epoch 10/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0150 - _calculate_reconstruction_loss: 0.0103 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.9742\n",
      "Epoch 11/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0138 - _calculate_reconstruction_loss: 0.0098 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 1.2567\n",
      "Epoch 12/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0131 - _calculate_reconstruction_loss: 0.0095 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.3484\n",
      "Epoch 13/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0128 - _calculate_reconstruction_loss: 0.0091 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.3665\n",
      "Epoch 14/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0123 - _calculate_reconstruction_loss: 0.0089 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.1892\n",
      "Epoch 15/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0124 - _calculate_reconstruction_loss: 0.0086 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.5860\n",
      "Epoch 16/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0112 - _calculate_reconstruction_loss: 0.0082 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 0.7951\n",
      "Epoch 17/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0118 - _calculate_reconstruction_loss: 0.0080 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.2174\n",
      "Epoch 18/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0117 - _calculate_reconstruction_loss: 0.0078 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.2010\n",
      "Epoch 19/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0114 - _calculate_reconstruction_loss: 0.0076 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 1.3489\n",
      "Epoch 20/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0107 - _calculate_reconstruction_loss: 0.0073 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.2195\n",
      "Epoch 21/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0112 - _calculate_reconstruction_loss: 0.0073 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.3122\n",
      "Epoch 22/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0104 - _calculate_reconstruction_loss: 0.0071 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 0.9300\n",
      "Epoch 23/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0104 - _calculate_reconstruction_loss: 0.0068 - _calculate_porosity_loss: 0.0020 - _calculate_kl_loss: 1.4753\n",
      "Epoch 24/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0110 - _calculate_reconstruction_loss: 0.0067 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 1.9184\n",
      "Epoch 25/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0102 - _calculate_reconstruction_loss: 0.0065 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.6845\n",
      "Epoch 26/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0096 - _calculate_reconstruction_loss: 0.0064 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 0.9501\n",
      "Epoch 27/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0100 - _calculate_reconstruction_loss: 0.0062 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.6256\n",
      "Epoch 28/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0095 - _calculate_reconstruction_loss: 0.0062 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.2143\n",
      "Epoch 29/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0089 - _calculate_reconstruction_loss: 0.0060 - _calculate_porosity_loss: 0.0020 - _calculate_kl_loss: 0.9413\n",
      "Epoch 30/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0094 - _calculate_reconstruction_loss: 0.0060 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.2872\n",
      "currently working one voxel : 5, voxels left : 53 \n",
      "Train on 249 samples\n",
      "Epoch 1/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0332 - _calculate_reconstruction_loss: 0.0276 - _calculate_porosity_loss: 0.0043 - _calculate_kl_loss: 1.1726\n",
      "Epoch 2/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0264 - _calculate_reconstruction_loss: 0.0217 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.9411\n",
      "Epoch 3/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0227 - _calculate_reconstruction_loss: 0.0180 - _calculate_porosity_loss: 0.0030 - _calculate_kl_loss: 1.7082\n",
      "Epoch 4/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0204 - _calculate_reconstruction_loss: 0.0156 - _calculate_porosity_loss: 0.0033 - _calculate_kl_loss: 1.4998\n",
      "Epoch 5/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0180 - _calculate_reconstruction_loss: 0.0142 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 1.1812\n",
      "Epoch 6/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0184 - _calculate_reconstruction_loss: 0.0133 - _calculate_porosity_loss: 0.0040 - _calculate_kl_loss: 1.1152\n",
      "Epoch 7/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0171 - _calculate_reconstruction_loss: 0.0122 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 2.0014\n",
      "Epoch 8/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0169 - _calculate_reconstruction_loss: 0.0115 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 2.7250\n",
      "Epoch 9/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0158 - _calculate_reconstruction_loss: 0.0110 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 2.2510\n",
      "Epoch 10/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0153 - _calculate_reconstruction_loss: 0.0103 - _calculate_porosity_loss: 0.0031 - _calculate_kl_loss: 1.7815\n",
      "Epoch 11/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0143 - _calculate_reconstruction_loss: 0.0100 - _calculate_porosity_loss: 0.0030 - _calculate_kl_loss: 1.3365\n",
      "Epoch 12/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0134 - _calculate_reconstruction_loss: 0.0096 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.0664\n",
      "Epoch 13/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0141 - _calculate_reconstruction_loss: 0.0093 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 1.8971\n",
      "Epoch 14/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0135 - _calculate_reconstruction_loss: 0.0089 - _calculate_porosity_loss: 0.0030 - _calculate_kl_loss: 1.5374\n",
      "Epoch 15/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0136 - _calculate_reconstruction_loss: 0.0088 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 1.8406\n",
      "Epoch 16/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0125 - _calculate_reconstruction_loss: 0.0084 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.4814\n",
      "Epoch 17/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0125 - _calculate_reconstruction_loss: 0.0083 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.3839\n",
      "Epoch 18/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0117 - _calculate_reconstruction_loss: 0.0080 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.0688\n",
      "Epoch 19/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0116 - _calculate_reconstruction_loss: 0.0076 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.5984\n",
      "Epoch 20/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0112 - _calculate_reconstruction_loss: 0.0075 - _calculate_porosity_loss: 0.0026 - _calculate_kl_loss: 1.0437\n",
      "Epoch 21/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0114 - _calculate_reconstruction_loss: 0.0074 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.1517\n",
      "Epoch 22/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0106 - _calculate_reconstruction_loss: 0.0071 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.3009\n",
      "Epoch 23/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0106 - _calculate_reconstruction_loss: 0.0069 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.4577\n",
      "Epoch 24/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0099 - _calculate_reconstruction_loss: 0.0067 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.0767\n",
      "Epoch 25/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0102 - _calculate_reconstruction_loss: 0.0067 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.1687\n",
      "Epoch 26/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0100 - _calculate_reconstruction_loss: 0.0064 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.4530\n",
      "Epoch 27/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0099 - _calculate_reconstruction_loss: 0.0063 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 1.3136\n",
      "Epoch 28/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0099 - _calculate_reconstruction_loss: 0.0062 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 1.3629\n",
      "Epoch 29/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0093 - _calculate_reconstruction_loss: 0.0060 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 0.9960\n",
      "Epoch 30/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0091 - _calculate_reconstruction_loss: 0.0058 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.1683\n",
      "currently working one voxel : 6, voxels left : 52 \n",
      "Train on 249 samples\n",
      "Epoch 1/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0327 - _calculate_reconstruction_loss: 0.0282 - _calculate_porosity_loss: 0.0032 - _calculate_kl_loss: 1.2032\n",
      "Epoch 2/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0246 - _calculate_reconstruction_loss: 0.0216 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 0.8030\n",
      "Epoch 3/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0209 - _calculate_reconstruction_loss: 0.0175 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 0.9206\n",
      "Epoch 4/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0194 - _calculate_reconstruction_loss: 0.0154 - _calculate_porosity_loss: 0.0031 - _calculate_kl_loss: 0.8994\n",
      "Epoch 5/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0173 - _calculate_reconstruction_loss: 0.0138 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 0.8299\n",
      "Epoch 6/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0162 - _calculate_reconstruction_loss: 0.0127 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.0130\n",
      "Epoch 7/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0161 - _calculate_reconstruction_loss: 0.0120 - _calculate_porosity_loss: 0.0030 - _calculate_kl_loss: 1.1181\n",
      "Epoch 8/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0153 - _calculate_reconstruction_loss: 0.0114 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.1662\n",
      "Epoch 9/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0143 - _calculate_reconstruction_loss: 0.0108 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 0.8254\n",
      "Epoch 10/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0139 - _calculate_reconstruction_loss: 0.0102 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 0.8764\n",
      "Epoch 11/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0138 - _calculate_reconstruction_loss: 0.0099 - _calculate_porosity_loss: 0.0028 - _calculate_kl_loss: 1.0789\n",
      "Epoch 12/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0132 - _calculate_reconstruction_loss: 0.0096 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.0898\n",
      "Epoch 13/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0117 - _calculate_reconstruction_loss: 0.0090 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 0.3989\n",
      "Epoch 14/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0120 - _calculate_reconstruction_loss: 0.0086 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 0.9499\n",
      "Epoch 15/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0116 - _calculate_reconstruction_loss: 0.0084 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 0.8251\n",
      "Epoch 16/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0112 - _calculate_reconstruction_loss: 0.0081 - _calculate_porosity_loss: 0.0023 - _calculate_kl_loss: 0.7534\n",
      "Epoch 17/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0115 - _calculate_reconstruction_loss: 0.0080 - _calculate_porosity_loss: 0.0025 - _calculate_kl_loss: 1.0685\n",
      "Epoch 18/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0108 - _calculate_reconstruction_loss: 0.0076 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 0.9834\n",
      "Epoch 19/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0110 - _calculate_reconstruction_loss: 0.0075 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 0.8520\n",
      "Epoch 20/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0102 - _calculate_reconstruction_loss: 0.0071 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 0.8808\n",
      "Epoch 21/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0101 - _calculate_reconstruction_loss: 0.0069 - _calculate_porosity_loss: 0.0020 - _calculate_kl_loss: 1.1572\n",
      "Epoch 22/30\n",
      "249/249 [==============================] - 4s 15ms/sample - loss: 0.0101 - _calculate_reconstruction_loss: 0.0068 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 0.9494\n",
      "Epoch 23/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0096 - _calculate_reconstruction_loss: 0.0066 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 0.8056\n",
      "Epoch 24/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0099 - _calculate_reconstruction_loss: 0.0064 - _calculate_porosity_loss: 0.0024 - _calculate_kl_loss: 1.1304\n",
      "Epoch 25/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0092 - _calculate_reconstruction_loss: 0.0062 - _calculate_porosity_loss: 0.0020 - _calculate_kl_loss: 1.0511\n",
      "Epoch 26/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0091 - _calculate_reconstruction_loss: 0.0061 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 0.8535\n",
      "Epoch 27/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0092 - _calculate_reconstruction_loss: 0.0060 - _calculate_porosity_loss: 0.0022 - _calculate_kl_loss: 1.1160\n",
      "Epoch 28/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0086 - _calculate_reconstruction_loss: 0.0057 - _calculate_porosity_loss: 0.0020 - _calculate_kl_loss: 0.9504\n",
      "Epoch 29/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0087 - _calculate_reconstruction_loss: 0.0056 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.0249\n",
      "Epoch 30/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0083 - _calculate_reconstruction_loss: 0.0055 - _calculate_porosity_loss: 0.0020 - _calculate_kl_loss: 0.8438\n",
      "currently working one voxel : 7, voxels left : 51 \n",
      "Train on 249 samples\n",
      "Epoch 1/30\n",
      "249/249 [==============================] - 4s 16ms/sample - loss: 0.0344 - _calculate_reconstruction_loss: 0.0300 - _calculate_porosity_loss: 0.0034 - _calculate_kl_loss: 0.9201\n",
      "Epoch 2/30\n",
      " 80/249 [========>.....................] - ETA: 2s - loss: 0.0277 - _calculate_reconstruction_loss: 0.0245 - _calculate_porosity_loss: 0.0021 - _calculate_kl_loss: 1.0573"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 66\u001b[0m\n\u001b[0;32m     56\u001b[0m UB \u001b[39m=\u001b[39m [\u001b[39m5.99\u001b[39m , \u001b[39m0.01\u001b[39m  , \u001b[39m6.99\u001b[39m, \u001b[39m4.99\u001b[39m  ,  \u001b[39m8.99\u001b[39m,  \u001b[39m8.99\u001b[39m , \u001b[39m9.99\u001b[39m ]\n\u001b[0;32m     58\u001b[0m problem_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m     59\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfit_func\u001b[39m\u001b[39m\"\u001b[39m: objective_function,\n\u001b[0;32m     60\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlb\u001b[39m\u001b[39m\"\u001b[39m: LB,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     64\u001b[0m }\n\u001b[1;32m---> 66\u001b[0m model \u001b[39m=\u001b[39m GWO\u001b[39m.\u001b[39;49mBaseGWO(problem_dict,epoch\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,pop_size\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n\u001b[0;32m     67\u001b[0m model\u001b[39m.\u001b[39msolve()\n\u001b[0;32m     68\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest solution : \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39msolution[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\mealpy\\swarm_based\\GWO.py:52\u001b[0m, in \u001b[0;36mBaseGWO.__init__\u001b[1;34m(self, problem, epoch, pop_size, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, problem, epoch\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m, pop_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m        problem (dict): The problem dictionary\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m        epoch (int): maximum number of iterations, default = 10000\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m        pop_size (int): number of population size, default = 100\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(problem, kwargs)\n\u001b[0;32m     53\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidator\u001b[39m.\u001b[39mcheck_int(\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m, epoch, [\u001b[39m1\u001b[39m, \u001b[39m100000\u001b[39m])\n\u001b[0;32m     54\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpop_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidator\u001b[39m.\u001b[39mcheck_int(\u001b[39m\"\u001b[39m\u001b[39mpop_size\u001b[39m\u001b[39m\"\u001b[39m, pop_size, [\u001b[39m10\u001b[39m, \u001b[39m10000\u001b[39m])\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\mealpy\\optimizer.py:68\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, problem, kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_keyword_arguments(kwargs)\n\u001b[1;32m---> 68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem \u001b[39m=\u001b[39m Problem(problem\u001b[39m=\u001b[39;49mproblem)\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamend_position \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem\u001b[39m.\u001b[39mamend_position\n\u001b[0;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_position \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem\u001b[39m.\u001b[39mgenerate_position\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\mealpy\\utils\\problem.py:86\u001b[0m, in \u001b[0;36mProblem.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_keyword_arguments(kwargs)\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m Logger(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_to, log_file\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_file)\u001b[39m.\u001b[39mcreate_logger(name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m     format_str\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%(asctime)s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%(levelname)s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m [line: \u001b[39m\u001b[39m%(lineno)d\u001b[39;00m\u001b[39m]: \u001b[39m\u001b[39m%(message)s\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__check_problem(kwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\mealpy\\utils\\problem.py:98\u001b[0m, in \u001b[0;36mProblem.__check_problem\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfit_func\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mand\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mlb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mand\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mub\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m     97\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_keyword_arguments(kwargs[\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__set_problem(kwargs[\u001b[39m\"\u001b[39;49m\u001b[39mproblem\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mDefined a problem dictionary with at least \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfit_func\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mub\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\mealpy\\utils\\problem.py:109\u001b[0m, in \u001b[0;36mProblem.__set_problem\u001b[1;34m(self, problem)\u001b[0m\n\u001b[0;32m    107\u001b[0m lb, ub, fit_func \u001b[39m=\u001b[39m problem[\u001b[39m\"\u001b[39m\u001b[39mlb\u001b[39m\u001b[39m\"\u001b[39m], problem[\u001b[39m\"\u001b[39m\u001b[39mub\u001b[39m\u001b[39m\"\u001b[39m], problem[\u001b[39m\"\u001b[39m\u001b[39mfit_func\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_domain_range(lb, ub, problem)\n\u001b[1;32m--> 109\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__set_fitness_function(fit_func, problem)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\mealpy\\utils\\problem.py:164\u001b[0m, in \u001b[0;36mProblem.__set_fitness_function\u001b[1;34m(self, fit_func, kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mPlease enter your \u001b[39m\u001b[39m'\u001b[39m\u001b[39mamend_position\u001b[39m\u001b[39m'\u001b[39m\u001b[39m as a callable function, and it needs to return amended solution.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m         exit(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 164\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_func(tested_solution)\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(result, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_objs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[36], line 47\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(solution)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(learnedVoxels)):\n\u001b[0;32m     46\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcurrently working one voxel : \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, voxels left : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(learnedVoxels)\u001b[39m-\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m     histories\u001b[39m.\u001b[39mappend(reconstruction\u001b[39m.\u001b[39;49mtrain(learnedVoxels[i],inferenceVoxels[i]))\n\u001b[0;32m     49\u001b[0m reconstruction\u001b[39m.\u001b[39msave(save_folder\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel_\u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mopt\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mnum_filters\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mlatent_space_dim\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mreduced_dim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m histories[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[24], line 77\u001b[0m, in \u001b[0;36mReconstruction.train\u001b[1;34m(self, inputs1, inputs2)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, inputs1,inputs2):\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mReconstruction\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49m[inputs1,inputs2],\n\u001b[0;32m     78\u001b[0m                    y\u001b[39m=\u001b[39;49minputs2,\n\u001b[0;32m     79\u001b[0m                    batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m     80\u001b[0m                    epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs,\n\u001b[0;32m     81\u001b[0m                    )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:795\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m'\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    794\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 795\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    796\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    797\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    798\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    799\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    800\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    801\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    802\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    803\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    804\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m    805\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    806\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    807\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    808\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    809\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    810\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    811\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    812\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m    813\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m    814\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:644\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`validation_steps` should not be specified if \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    641\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m`validation_data` is None.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    642\u001b[0m   val_x, val_y, val_sample_weights \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mreturn\u001b[39;00m fit_loop(\n\u001b[0;32m    645\u001b[0m     model,\n\u001b[0;32m    646\u001b[0m     inputs\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    647\u001b[0m     targets\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    648\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weights,\n\u001b[0;32m    649\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    650\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    651\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    652\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    653\u001b[0m     val_inputs\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m    654\u001b[0m     val_targets\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m    655\u001b[0m     val_sample_weights\u001b[39m=\u001b[39;49mval_sample_weights,\n\u001b[0;32m    656\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    657\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    658\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    659\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    660\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    661\u001b[0m     steps_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:380\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m callbacks\u001b[39m.\u001b[39m_call_batch_hook(mode, \u001b[39m'\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m'\u001b[39m, batch_index, batch_logs)\n\u001b[0;32m    379\u001b[0m \u001b[39m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 380\u001b[0m batch_outs \u001b[39m=\u001b[39m f(ins_batch)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_outs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    382\u001b[0m   batch_outs \u001b[39m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4054\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4048\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m feed_arrays \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_arrays \u001b[39mor\u001b[39;00m\n\u001b[0;32m   4049\u001b[0m     symbol_vals \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_symbol_vals \u001b[39mor\u001b[39;00m\n\u001b[0;32m   4050\u001b[0m     feed_symbols \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_symbols \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetches \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches \u001b[39mor\u001b[39;00m\n\u001b[0;32m   4051\u001b[0m     session \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session):\n\u001b[0;32m   4052\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4054\u001b[0m fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_callable_fn(\u001b[39m*\u001b[39;49marray_vals,\n\u001b[0;32m   4055\u001b[0m                             run_metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_metadata)\n\u001b[0;32m   4056\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches):])\n\u001b[0;32m   4057\u001b[0m output_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4059\u001b[0m     fetched[:\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)],\n\u001b[0;32m   4060\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\PFE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1480\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1479\u001b[0m   run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1480\u001b[0m   ret \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39;49mTF_SessionRunCallable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_session,\n\u001b[0;32m   1481\u001b[0m                                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, args,\n\u001b[0;32m   1482\u001b[0m                                          run_metadata_ptr)\n\u001b[0;32m   1483\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1484\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from mealpy.swarm_based import GWO\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "OPT_ENCODER = LabelEncoder()\n",
    "OPT_ENCODER.fit(['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'])\n",
    "\n",
    "\n",
    "def decode_solution(solution):\n",
    "    batch_size = 2**int(solution[0])\n",
    "    \n",
    "    learning_rate = solution[1]\n",
    "    \n",
    "    opt_int = int(solution[2])\n",
    "    opt = OPT_ENCODER.inverse_transform([opt_int])[0]\n",
    "    \n",
    "    epoch = 10 *int(solution[3])\n",
    "    \n",
    "    num_filters = int(solution[4])\n",
    "    \n",
    "    latent_space_dim = 2**int(solution[5])\n",
    "    \n",
    "    reduced_dim = 2**int(solution[6])\n",
    "    \n",
    "    return [batch_size,learning_rate,opt,epoch,num_filters,latent_space_dim,reduced_dim]\n",
    "\n",
    "\n",
    "def objective_function(solution):\n",
    "    tf.keras.backend.clear_session()\n",
    "    batch_size,learning_rate,opt,epoch,num_filters,latent_space_dim ,reduced_dim = decode_solution(solution)\n",
    "    reconstruction = Reconstruction(inputShape=CONFIGURATION[\"INPUT_SHAPE\"],\n",
    "                                     latent_space_dim = latent_space_dim,\n",
    "                                     reducedDimension = reduced_dim,\n",
    "                                     num_conv_layers = num_filters,\n",
    "                                     learning_rate = learning_rate,\n",
    "                                     batch_size = batch_size,\n",
    "                                     epochs = epoch,\n",
    "                                     opt = opt,\n",
    "                                   )\n",
    "#     reconstruction.summary()\n",
    "    reconstruction.compile()\n",
    "    \n",
    "    \n",
    "    histories = []\n",
    "    for i in range(len(learnedVoxels)):\n",
    "        print(f\"currently working one voxel : {i +1}, voxels left : {len(learnedVoxels)-(i+1)} \")\n",
    "        histories.append(reconstruction.train(learnedVoxels[i],inferenceVoxels[i]))\n",
    "    \n",
    "    reconstruction.save(save_folder=f\"model_{batch_size}_{learning_rate}_{opt}_{epoch}_{num_filters}_{latent_space_dim}_{reduced_dim}\")\n",
    "    \n",
    "    return histories[-1].history['loss'][-1]\n",
    "    \n",
    "    \n",
    "\n",
    "LB = [3    , 0.001 , 0   , 2      ,  4  ,  6    , 7 ]\n",
    "UB = [5.99 , 0.01  , 6.99, 4.99  ,  8.99,  8.99 , 9.99 ]\n",
    "\n",
    "problem_dict = {\n",
    "    \"fit_func\": objective_function,\n",
    "    \"lb\": LB,\n",
    "    \"ub\": UB,\n",
    "    \"minmax\": \"min\",\n",
    "    \"verbose\":True,\n",
    "}\n",
    "\n",
    "model = GWO.BaseGWO(problem_dict,epoch=5,pop_size=50)\n",
    "model.solve()\n",
    "print(f\"Best solution : {model.solution[0]}\")\n",
    "batch_size,learning_rate,opt,epoch,num_filters,latent_space_dim ,reduced_dim = decode_solution(model.solution[0])\n",
    "print(f\"Batch size : {batch_size}, learning_rate : {learning_rate}, opt : {opt}, epoch : {epoch}, num_filters : {num_filters}, latent_space_dim : {latent_space_dim}, reduced_dim : {reduced_dim}\")\n",
    "model.history.save_global_objectives_chart(filename=\"hello/goc\")\n",
    "model.history.save_local_objectives_chart(filename=\"hello/loc\")\n",
    "\n",
    "model.history.save_global_best_fitness_chart(filename=\"hello/gbfc\")\n",
    "model.history.save_local_best_fitness_chart(filename=\"hello/lbfc\")\n",
    "\n",
    "model.history.save_runtime_chart(filename=\"hello/rtc\")\n",
    "\n",
    "model.history.save_exploration_exploitation_chart(filename=\"hello/eec\")\n",
    "\n",
    "model.history.save_diversity_chart(filename=\"hello/dc\")\n",
    "\n",
    "model.history.save_trajectory_chart(list_agent_idx=[3, 5], selected_dimensions=[3], filename=\"hello/tc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b389ee33",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30a0b3c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently working one voxel : 1, voxels left : 2 \n",
      "Train on 249 samples\n",
      "Epoch 1/2\n",
      "249/249 [==============================] - 15s 61ms/sample - loss: 0.3050 - _calculate_reconstruction_loss: 0.1250 - _calculate_porosity_loss: 0.1475 - _calculate_kl_loss: 29.0457\n",
      "Epoch 2/2\n",
      "249/249 [==============================] - 2s 10ms/sample - loss: 0.1088 - _calculate_reconstruction_loss: 0.0443 - _calculate_porosity_loss: 0.0390 - _calculate_kl_loss: 24.7899\n",
      "currently working one voxel : 2, voxels left : 1 \n",
      "Train on 249 samples\n",
      "Epoch 1/2\n",
      "249/249 [==============================] - 2s 10ms/sample - loss: 0.0672 - _calculate_reconstruction_loss: 0.0311 - _calculate_porosity_loss: 0.0074 - _calculate_kl_loss: 28.4738\n",
      "Epoch 2/2\n",
      "249/249 [==============================] - 2s 10ms/sample - loss: 0.0552 - _calculate_reconstruction_loss: 0.0272 - _calculate_porosity_loss: 0.0029 - _calculate_kl_loss: 25.0498\n",
      "currently working one voxel : 3, voxels left : 0 \n",
      "Train on 249 samples\n",
      "Epoch 1/2\n",
      "249/249 [==============================] - 2s 10ms/sample - loss: 0.0569 - _calculate_reconstruction_loss: 0.0254 - _calculate_porosity_loss: 0.0040 - _calculate_kl_loss: 27.4741\n",
      "Epoch 2/2\n",
      "249/249 [==============================] - 2s 10ms/sample - loss: 0.0536 - _calculate_reconstruction_loss: 0.0249 - _calculate_porosity_loss: 0.0027 - _calculate_kl_loss: 26.1224\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for i in range(3):\n",
    "    print(f\"currently working one voxel : {i +1}, voxels left : {3-(i+1)} \")\n",
    "    histories.append(reconstruction.train(learnedVoxels[i],inferenceVoxels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fd13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(histories[-1].history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c86648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a22db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdf07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = Reconstruction.load(save_folder=f\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e56a1190",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first  = X_test[0]\n",
    "Topredict = first[1:]\n",
    "test = first[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ac3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = []\n",
    "\n",
    "\n",
    "# # for i in range(10):\n",
    "# predicted = reconstruction.Generate.predict([test,Topredict])\n",
    "# # predicted.append(nextLayer)\n",
    "# # #     inputLayer = nextLayer\n",
    "# # predicted.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7297fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.compat.v1.Session()\n",
    "# predictedValues = []\n",
    "# for i in range (10):\n",
    "# # Evaluate the tensor and get its value\n",
    "#     predictedValues.append(sess.run(predicted[i+1]))\n",
    "\n",
    "\n",
    "# # Close the session\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 10\n",
    "\n",
    "# plt.figure(figsize=(20,4))\n",
    "# for i in range(n):\n",
    "#     # original\n",
    "#     ax = plt.subplot(2,n,i+1)\n",
    "#     plt.imshow(Topredict[i].astype(\"float32\"))\n",
    "#     plt.title('original')\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "\n",
    "#     # reconstructed\n",
    "#     ax = plt.subplot(2,n,i+1+n)\n",
    "#     plt.imshow(predicted[i].astype(\"float32\"))\n",
    "#     plt.title('reconstructed')\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9eb391",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = []\n",
    "inputLayer = first[0]\n",
    "# for i in range(len(first)-1):\n",
    "for i in range(10):\n",
    "\n",
    "    learned = reconstruction.learnedPrior(inputLayer.reshape(1,256,256,1))\n",
    "    testing.append(reconstruction.Generate.predict([inputLayer.reshape(1,256,256,1),learned],steps=1))\n",
    "    inputLayer = testing[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af24ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    # original\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(Topredict[i].astype(\"float32\"))\n",
    "    plt.title('original')\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # reconstructed\n",
    "    ax = plt.subplot(2,n,i+1+n)\n",
    "    plt.imshow(testing[i].reshape(256,256,1))\n",
    "    plt.title('reconstructed')\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction.Generate.save('reconstruction_10batch_10epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"reconstructed.raw\"\n",
    "testing.insert(0, first[0].reshape(1,256,256,1))\n",
    "print(len(testing))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.array(testing,np.float32).reshape(250,256,256)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"my_array.npy\"\n",
    "np.save(\"file\", final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.tofile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149818c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Volume = np.fromfile(file_path, dtype=np.uint8)\n",
    "Volume = Volume.reshape(250,256,256)\n",
    "Volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2803d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
